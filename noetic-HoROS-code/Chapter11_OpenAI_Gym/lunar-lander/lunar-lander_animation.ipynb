{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 100 steps (frames) of one episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "# env.render()\n",
    "env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "for _ in range(100):\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)\n",
    "    # sleep(0.1)\n",
    "    \n",
    "print 'Simulation finished'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run a training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from keras import Sequential\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.activations import relu, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "\n",
    "    \"\"\" Implementation of deep q learning algorithm \"\"\"\n",
    "\n",
    "    def __init__(self, action_space, state_space):\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.epsilon = 1.0\n",
    "        self.gamma = .99\n",
    "        self.batch_size = 64\n",
    "        self.epsilon_min = .01\n",
    "        self.lr = 0.001\n",
    "        self.epsilon_decay = .996\n",
    "        self.memory = deque(maxlen=1000000)\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(150, input_dim=self.state_space, activation=relu))\n",
    "        model.add(Dense(120, activation=relu))\n",
    "        model.add(Dense(self.action_space, activation=linear))\n",
    "        model.compile(loss='mse', optimizer=adam(lr=self.lr))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_space)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self):\n",
    "\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([i[0] for i in minibatch])\n",
    "        actions = np.array([i[1] for i in minibatch])\n",
    "        rewards = np.array([i[2] for i in minibatch])\n",
    "        next_states = np.array([i[3] for i in minibatch])\n",
    "        dones = np.array([i[4] for i in minibatch])\n",
    "\n",
    "        states = np.squeeze(states)\n",
    "        next_states = np.squeeze(next_states)\n",
    "\n",
    "        targets = rewards + self.gamma*(np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones)\n",
    "        targets_full = self.model.predict_on_batch(states)\n",
    "        ind = np.array([i for i in range(self.batch_size)])\n",
    "        targets_full[[ind], [actions]] = targets\n",
    "\n",
    "        self.model.fit(states, targets_full, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(episode):\n",
    "\n",
    "    loss = []\n",
    "    agent = DQN(env.action_space.n, env.observation_space.shape[0])\n",
    "    for e in range(episode):\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, (1, 8))\n",
    "        score = 0\n",
    "        max_steps = 3000\n",
    "        for i in range(max_steps):\n",
    "            action = agent.act(state)\n",
    "            env.render()\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            next_state = np.reshape(next_state, (1, 8))\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            agent.replay()\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, score: {}\".format(e, episode, score))\n",
    "                break\n",
    "        loss.append(score)\n",
    "\n",
    "        # Average score of last 100 episode\n",
    "        is_solved = np.mean(loss[-100:])\n",
    "        if is_solved > 200:\n",
    "            print('\\n Task Completed! \\n')\n",
    "            break\n",
    "        print(\"Average over last 100 episode: {0:.2f} \\n\".format(is_solved))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(8,)\n",
      "Discrete(4)\n",
      "WARNING:tensorflow:From /home/bernardo/anaconda2/envs/gym/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "episode: 0/400, score: -130.282375017\n",
      "Average over last 100 episode: -130.28 \n",
      "\n",
      "episode: 1/400, score: -44.1590847225\n",
      "Average over last 100 episode: -87.22 \n",
      "\n",
      "episode: 2/400, score: -273.133245234\n",
      "Average over last 100 episode: -149.19 \n",
      "\n",
      "episode: 3/400, score: -131.229418953\n",
      "Average over last 100 episode: -144.70 \n",
      "\n",
      "episode: 4/400, score: -254.79938886\n",
      "Average over last 100 episode: -166.72 \n",
      "\n",
      "episode: 5/400, score: -158.297363623\n",
      "Average over last 100 episode: -165.32 \n",
      "\n",
      "episode: 6/400, score: -53.9282125416\n",
      "Average over last 100 episode: -149.40 \n",
      "\n",
      "episode: 7/400, score: -428.280246208\n",
      "Average over last 100 episode: -184.26 \n",
      "\n",
      "episode: 8/400, score: -24.2461627188\n",
      "Average over last 100 episode: -166.48 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(env.observation_space)\n",
    "    print(env.action_space)\n",
    "    episodes = 400\n",
    "    loss = train_dqn(episodes)\n",
    "    plt.plot([i+1 for i in range(0, len(loss), 2)], loss[::2])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
